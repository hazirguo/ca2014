---
layout: post
title: 第四次作业发布，请与4月9日交！
---


**第四次作业请在 4 月 9 日上课前交，逾期不再接收！**

## B1

You are trying to appreciate how important the principle of
locality  is  in  justifying  the  use  of  a  cache  memory,  so  you  experiment  with  a
computer having an L1 data cache and a main memory (you exclusively focus on
data accesses). The latencies (in CPU cycles) of the different kinds of accesses
are as follows: cache hit, 1 cycle; cache miss, 105 cycles; main memory access
with cache disabled, 100 cycles.

a. When you run a program with an overall miss rate of 5%, what
will the average memory access time (in CPU cycles) be?

b. Next, you run a program specifically designed to produce completely 
 random data addresses with no locality. Toward that end, you use an
array of size 256 MB (all of it fits in the main memory). Accesses to random
elements of this array are continuously made (using a uniform random number
generator to generate the elements indices). If your data cache size is 64 KB,
what will the average memory access time be?

c. If you compare the result obtained in part (b) with the main memory 
access time when the cache is disabled, what can you conclude about the
role of the principle of locality in justifying the use of cache memory?

d. You observed that a cache hit produces a gain of 99 cycles (1 cycle
vs. 100), but it produces a loss of 5 cycles in the case of a miss (105 cycles vs.
100). In the general case, we can express these two quantities as G (gain) and
L (loss). Using these two quantities (G and L), identify the highest miss rate
after which the cache use would be disadvantageous.


## B3

 Cache organization is often influenced by the
desire to reduce the cache’s power consumption. For that purpose we assume that
the cache is physically distributed into a data array (holding the data), tag array
(holding  the  tags),  and  replacement  array  (holding  information  needed  by
replacement policy). Furthermore, every one of these arrays is physically distrib-
uted into multiple sub-arrays (one per way) that can be individually accessed; for
example, a four-way set associative least recently used (LRU) cache would have
four data sub-arrays, four tag  sub-arrays,  and four replacement  sub-arrays. We
assume that the replacement sub-arrays are accessed once per access when the
LRU replacement policy is used, and once per miss if the first-in, first-out (FIFO)
replacement policy is used. It is not needed when a random replacement policy is
used.  For  a  specific cache,  it was determined that the accesses  to  the  different
arrays have the following power consumption weights:


| Array |  Power consumption weight (per way accessed) |
|:------| :--------:| 
| Data array | 20 uints  |
| Tag Array  | 5 uints |
| Miscellaneous array | 1 uint |


Estimate the cache power usage (in power units) for the following configurations.
We  assume  the  cache  is  four-way  set  associative.  Main  memory  access  power—
albeit important—is not considered here. Provide answers for the LRU, FIFO, and
random replacement policies.

a. A cache read hit. All arrays are read simultaneously.

b. Repeat part (a) for a cache read miss.

c. Repeat part (a) assuming that the cache access is split across two
cycles. In  the first cycle, all the tag sub-arrays are accessed. In  the  second
cycle, only the sub-array whose tag matched will be accessed.

d. Repeat part (c) for a cache read miss (no data array accesses in the
second cycle).

e. Repeat part (c) assuming that logic is added to predict the cache
way to be accessed. Only the tag sub-array for the predicted way is accessed
in cycle one. A way hit (address match in predicted way) implies a cache hit.
A way miss dictates examining all the tag sub-arrays in the second cycle. In
case  of a  way hit, only  one  data  sub-array  (the  one whose  tag matched) is
accessed in cycle two. Assume there is way hit.

f. Repeat part (e) assuming that the way predictor missed (the way it
chose is wrong). When it fails, the way predictor adds an extra cycle in which
it accesses all the tag sub-arrays. Assume a cache read hit.

g. Repeat part (f) assuming a cache read miss.

h. Use parts (e), (f), and (g) for the general case where the work-
load has the following statistics: way-predictor miss rate = 5% and cache
miss rate = 3%. (Consider different replacement policies.)


## B4

 We  compare  the  write  bandwidth  requirements  of
write-through versus write-back caches using a concrete example. Let us assume
that we have a 64 KB cache with a line size of 32 bytes. The cache will allocate a
line on a write miss. If configured as a write-back cache, it will write back the
whole dirty line if it needs to be replaced. We will also assume that the cache is
connected to the lower level in the hierarchy through a 64-bit-wide (8-byte-wide)
bus. The number of CPU cycles for a B-bytes write access on this bus is
For example, an 8-byte write would take  cycles, whereas using
the same formula a 12-byte write would take 15 cycles. Answer the following
questions while referring to the C code snippet below:

	…
	#define PORTION 1 
	… 
	Base = 8*i; 
	for (unsigned int j=base; j < base+PORTION; j++) //assume j is stored in a register
		data[j] = j;


a.  For a write-through  cache, how  many CPU  cycles  are  spent on
write transfers to the memory for the all the combined iterations of the j loop?

b. If the cache is configured as a write-back cache, how many CPU
cycles are spent on writing back a cache line?

c.  Change PORTION to 8 and repeat part (a).

d. What is the minimum number of array updates to the same cache
line (before replacing it) that would render the write-back cache superior?

e. Think of a scenario where all the words of the cache line will be
written (not necessarily using the above code) and a write-through cache will
require fewer total CPU cycles than the write-back cache.



## B5

You  are  building  a  system  around  a  processor  with  inorder 
execution that runs at 1.1 GHz and has a CPI of 0.7 excluding memory
accesses. The only instructions that read or write data from memory are loads
(20% of all instructions) and stores (5% of all instructions). The memory sys-
tem for this computer is composed of a split L1 cache that imposes no penalty
on hits. Both the I-cache and D-cache are direct mapped and hold 32 KB each.
The I-cache has a 2% miss rate and 32-byte blocks, and the D-cache is write-
through with a 5% miss rate and 16-byte blocks. There is a write buffer on the
D-cache that eliminates stalls for 95% of all writes. The 512 KB write-back,
unified L2 cache has 64-byte blocks and an access time of 15 ns. It is connected
to the L1 cache by a 128-bit data bus that runs at 266 MHz and can transfer one
128-bit word per bus cycle. Of all memory references sent to the L2 cache in
this system, 80% are satisfied without going to main memory. Also, 50% of all
blocks replaced are dirty. The 128-bit-wide main memory has an access latency
of 60 ns, after which any number of bus words may be transferred at the rate of
one per cycle on the 128-bit-wide 133 MHz main memory bus.

a.  What is the average memory access time for instruction accesses?

b.  What is the average memory access time for data reads?

c.  What is the average memory access time for data writes?

d.  What is the overall CPI, including memory accesses?



## B6

 Converting  miss  rate  (misses  per  reference)  into  misses  per
instruction  relies  upon  two  factors:  references  per  instruction  fetched  and  the
fraction of fetched instructions that actually commits.

a.  The formula for misses per instruction on page B-5 is written first in
terms of three factors: miss rate, memory accesses, and instruction count. Each
of these factors represents actual events. What is different about writing misses
per instruction as miss rate times the factor memory accesses per instruction?

b.  Speculative processors will fetch instructions that do not commit.
The  formula  for  misses  per  instruction  on  page  B-5  refers  to  misses  per
instruction on the execution path, that is, only the instructions that must actu-
ally be executed to carry out the program. Convert the formula for misses per
instruction  on  page  B-5  into  one  that  uses  only  miss  rate,  references  per
instruction  fetched,  and  fraction  of  fetched  instructions  that  commit.  Why
rely upon these factors rather than those in the formula on page B-5?

c. The conversion in part (b) could yield an incorrect value to the
extent  that  the  value  of  the  factor  references  per  instruction  fetched  is  not
equal to the number of references for any particular instruction. Rewrite the
formula of part (b) to correct this deficiency.
